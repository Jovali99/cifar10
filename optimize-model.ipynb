{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0ae87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch import tensor, cat, save, load, optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from models.resnet18_model import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10e7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective\n",
    "def Objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -10, 10)\n",
    "    return x**2/(10-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820fa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(Objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ca3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f6148",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'da'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#-------------------#\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#  Prepare dataset  #\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#-------------------#\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mda\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloadDataset\u001b[39m(data_cfg):\n\u001b[32m      6\u001b[39m     dataset_name = data_cfg[\u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'da'"
     ]
    }
   ],
   "source": [
    "#-------------------#\n",
    "#  Prepare dataset  #\n",
    "#-------------------#\n",
    "from dataset_handler import processDataset, loadDataset\n",
    "\n",
    "# Dataset config\n",
    "data_cfg = { \n",
    "            \"dataset\": \"cifar10\",\n",
    "            \"f_train\": \"0.5\",\n",
    "            \"f_test\": \"0.5\",\n",
    "            \"root\": \"./data\"\n",
    "            }\n",
    "\n",
    "trainset, testset = loadDataset(data_cfg)\n",
    "\n",
    "# Perpare loaders\n",
    "train_loader, test_loader, train_indices, test_indices = processDataset(train_cfg, trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------#\n",
    "#       Objective       #\n",
    "#-----------------------#\n",
    "def objective(trial):\n",
    "    # Hyperparameters\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.8, 0.99)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    T_max = trial.suggest_int(\"T_max\", 20, 50)\n",
    "\n",
    "    train_loader, val_loader = get_dataloaders(batch_size, args.augment)\n",
    "\n",
    "    model = torchvision.models.resnet18(num_classes=10).to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "\n",
    "    max_epochs = 50\n",
    "    for epoch in range(max_epochs):\n",
    "        train_one_epoch(model, optimizer, train_loader, DEVICE)\n",
    "        scheduler.step()\n",
    "        val_accuracy = evaluate(model, val_loader, DEVICE)\n",
    "        trial.report(val_accuracy, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_accuracy\n",
    "\n",
    "def train_one_epoch(model, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "# ---------------------------#\n",
    "#      Run optimization      #\n",
    "# ---------------------------#\n",
    "def run_optimization():\n",
    "    storage = JournalStorage(JournalFileBackend(file_path=\"./journal.log\"))\n",
    "    study = optuna.create_study(\n",
    "        study_name=args.study_name,\n",
    "        storage=storage,\n",
    "        load_if_exists=True,\n",
    "        direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, n_trials=args.n_trials)\n",
    "    print(f\"Study '{args.study_name}' completed. Best value: {study.best_value}, params: {study.best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce592c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ddc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training and config metadata. Folder name index-hashed_config/logits, metadata, etc\n",
    "form save-load import save, hashCfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train shadow models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

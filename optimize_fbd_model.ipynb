{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch import tensor, cat, save, load, optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.resnet18_model import ResNet18\n",
    "\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "\n",
    "import src.study_handler as sh\n",
    "from src.utils import print_yaml, get_shadow_signals, percentile_score_normalization\n",
    "from LeakPro.leakpro.attacks.mia_attacks.rmia import rmia_vectorised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. set device\n",
    "2. Load the study.yaml which contains the fbd_study key\n",
    "3. load baseline audit signals, shadow models logits, sm inmask and metadata\n",
    "4. Use metadata to update the training part of fbd_study\n",
    "5. Select sm to be used\n",
    "6. TODO Calc the vulnerability of the baseline model\n",
    "7. Normalize the vulnerability score\n",
    "8. Prepare the dataset using the baseline inmask to make sure we train on the baseline trainset\n",
    "9. Init the study and run it\n",
    "10. Visualize the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68780cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------#\n",
    "#  Set device  #\n",
    "# -------------#\n",
    "sh.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "#  Load Study Config  #\n",
    "#---------------------#\n",
    "config = None\n",
    "with open(\"./study.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print_yaml(f\"Initial study config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------#\n",
    "#  Load Model Signals  #\n",
    "#----------------------#\n",
    "audit_signals_folder = config[\"fbd_study\"][\"audit_signals_folder\"]\n",
    "metadata, rescaled_target_logits, rescaled_shadow_model_logits, shadow_models_in_mask, target_in_mask, audit_data_indices = loadAudit(audit_signals_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------#\n",
    "#  Update Study Config  #\n",
    "#-----------------------#\n",
    "print_yaml(f\"Initial study config: {config['fbd_study']}\")\n",
    "\n",
    "train_metadata = metadata[\"trainCfg\"][\"train\"]\n",
    "\n",
    "config['fbd_study'][\"epochs\"] = train_metadata[\"epochs\"]\n",
    "config['fbd_study'][\"batch_size\"] = train_metadata[\"batch_size\"]\n",
    "config['fbd_study'][\"momentum\"] = train_metadata[\"momentum\"]\n",
    "config['fbd_study'][\"learning_rate\"] = train_metadata[\"learning_rate\"]\n",
    "config['fbd_study'][\"t_max\"] = train_metadata[\"t_max\"]\n",
    "config['fbd_study'][\"weight_decay\"] = train_metadata[\"weight_decay\"]\n",
    "\n",
    "print_yaml(f\"Updated study config: {config['fbd_study']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce50bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------#\n",
    "#  Select Shadow Models  #\n",
    "#------------------------#\n",
    "sm_count = config['fbd_study']['shadow_model_count']\n",
    "print(f\"Shape of rescaled_sm_logits: {rescaled_shadow_model_logits.shape}\")\n",
    "shadow_logits, shadow_inmask = get_shadow_signals(rescaled_shadow_model_logits, shadow_models_in_mask, sm_count)\n",
    "print(f\"Shape of selected_sm_logits: {shadow_logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------#\n",
    "#  Calculate Vulnerability score using RMIA  #\n",
    "#--------------------------------------------#\n",
    "# This will by default be 8 as it achieves a strong attack result using few models, observed in Low-Cost High-Power Membership Inference Attacks page 7\n",
    "baseline_vulnerability_sm_count = 8\n",
    "baseline_vulnerability_shadow_logits, baseline_vulnerability_shadow_inmask = get_shadow_signals(rescaled_shadow_model_logits, shadow_models_in_mask, baseline_vulnerability_sm_count)\n",
    "\n",
    "# As seen in \n",
    "x_indices = # x_indices will be 50% of the dataset used\n",
    "z_indices = # 2500 are used as per the article, 2500 compared to 1250 gave ~0.68 better auc, 2500 compare to 6250 gve ~0.53% better auc\n",
    "rmia_scores = rmia_vectorised(rescaled_target_logits, baseline_vulnerability_shadow_logits, baseline_vulnerability_shadow_inmask, x_indices=x_indices, z_indices=z_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------#\n",
    "#  Normalize Vulnerability Scores  #\n",
    "#----------------------------------#\n",
    "percentile = 2\n",
    "norm_scores = percentile_score_normalization(rmia_scores, percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7457d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------#\n",
    "#  Prepare dataset  #\n",
    "#-------------------#\n",
    "from src.dataset_handler import processDataset, loadDataset\n",
    "data_cfg = config['data']\n",
    "trainset, testset = loadDataset(data_cfg)\n",
    "\n",
    "# Will split the dataset to use the same in indices as the baseline target model\n",
    "train_dataset, test_dataset, train_indices, test_indices = processDataset(data_cfg, trainset, testset, in_indices_mask=target_in_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97051e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------#\n",
    "#        Run study        #\n",
    "# ------------------------#\n",
    "import src.save_load as sl\n",
    "\n",
    "def run_optimization(config):\n",
    "    study_cfg = config['fbd_study']\n",
    "    \n",
    "    metadata = sl.buildStudyMetadata(study_cfg, config['data'])\n",
    "    _, save_path = sl.saveStudy(metadata, savePath=study_cfg['root'])\n",
    "    \n",
    "    journal_path = os.path.join(save_path, \"journal.log\")\n",
    "    storage = JournalStorage(JournalFileBackend(file_path=journal_path))\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=study_cfg[\"study_name\"],\n",
    "        storage=storage,\n",
    "        load_if_exists=True,\n",
    "        directions=[\"maximize\", \"minimize\"]\n",
    "    )\n",
    "    \n",
    "    func = lambda trial: sh.fbd_objective(trial, norm_scores, train_dataset, test_dataset,\n",
    "                                       config, shadow_logits, shadow_inmask )\n",
    "    \n",
    "    study.optimize(func, n_trials=study_cfg[\"trials\"])\n",
    "    \n",
    "    \n",
    "    print(f\"Study '{study_cfg['study_name']}' completed. Best value: {study.best_value}, params: {study.best_params}\")\n",
    "    \n",
    "    df = study.trials_dataframe()\n",
    "    df.to_csv(os.path.join(save_path, \"results.csv\"), index=False)\n",
    "    print(f\"ðŸ“„ Results saved to {os.path.join(save_path, 'results.csv')}\")\n",
    "\n",
    "    return study\n",
    "\n",
    "study = None\n",
    "if config is not None:\n",
    "    study = run_optimization(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if study is not None:\n",
    "    optuna.visualization.plot_pareto_front(study)\n",
    "    optuna.visualization.plot_param_importances(study)\n",
    "else:\n",
    "    print(\"Study has not been run\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

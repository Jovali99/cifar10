{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch import tensor, cat, save, load, optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "\n",
    "import src.study_handler as sh\n",
    "from src.utils import print_yaml, get_shadow_signals, calculate_tauc\n",
    "from LeakPro.leakpro.attacks.mia_attacks.rmia import rmia_vectorised, rmia_get_gtlprobs\n",
    "from src.save_load import loadTargetSignals, loadShadowModelSignals\n",
    "from src.models.resnet18_model import ResNet18\n",
    "from src.optimize_fbd_model import parallell_optimization\n",
    "from src.dataclasses import FbdArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "#  Load Study Config  #\n",
    "#---------------------#\n",
    "config = None\n",
    "with open(\"./study.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print_yaml(f\"Initial study config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------#\n",
    "#  Load Model Signals  #\n",
    "#----------------------#\n",
    "target_folder = config[\"fbd_study\"][\"target_folder\"]\n",
    "\n",
    "# Load target signals\n",
    "target_logits, target_inmask, metadata = loadTargetSignals(target_folder)\n",
    "print(f\"Target logits and inmask shapes: {target_logits.shape}, {target_inmask.shape}\")\n",
    "\n",
    "# Load processed shadow model signals\n",
    "sm_logits, sm_inmask = loadShadowModelSignals(target_folder)\n",
    "print(f\"Target logits and inmask shapes: {sm_logits.shape}, {sm_inmask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------#\n",
    "#  Update Study Config  #\n",
    "#-----------------------#\n",
    "print_yaml(\"Initial study config:\")\n",
    "print_yaml(config['fbd_study'])\n",
    "train_metadata = metadata[\"train\"]\n",
    "\n",
    "config['fbd_study'][\"epochs\"] = train_metadata[\"epochs\"]\n",
    "config['fbd_study'][\"batch_size\"] = train_metadata[\"batch_size\"]\n",
    "config['fbd_study'][\"momentum\"] = train_metadata[\"momentum\"]\n",
    "config['fbd_study'][\"learning_rate\"] = train_metadata[\"learning_rate\"]\n",
    "config['fbd_study'][\"t_max\"] = train_metadata[\"t_max\"]\n",
    "config['fbd_study'][\"weight_decay\"] = train_metadata[\"weight_decay\"]\n",
    "\n",
    "print_yaml(\"\\nUpdated study config:\")\n",
    "print_yaml(config['fbd_study'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce50bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------#\n",
    "#  Select Shadow Models  #\n",
    "#------------------------#\n",
    "sm_count = config['fbd_study']['shadow_model_count']\n",
    "print(f\"Randomly selecting {sm_count} to be used for the study.\")\n",
    "shadow_logits, shadow_inmask = get_shadow_signals(sm_logits, sm_inmask, sm_count)\n",
    "print(f\"Shape of selected_sm_logits: {shadow_logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------#\n",
    "#  Prepare dataset  #\n",
    "#-------------------#\n",
    "from src.dataset_handler import processDataset, loadDataset\n",
    "data_cfg = config['data']\n",
    "trainset, testset = loadDataset(data_cfg)\n",
    "\n",
    "# Will split the dataset to use the same in indices as the baseline target model\n",
    "train_dataset, test_dataset, train_indices, test_indices = processDataset(data_cfg, trainset, testset, in_indices_mask=target_inmask)\n",
    "\n",
    "# Retrieve the targets\n",
    "full_dataset = train_dataset.dataset\n",
    "labels = full_dataset.targets\n",
    "print(f\"Length of dataset targets/labels: {len(labels)}\")\n",
    "print(f\"First 10 targets/labels: {labels[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------#\n",
    "#  Calculate Vulnerability score using RMIA  #\n",
    "#--------------------------------------------#\n",
    "# Calculate the GTL Probabilities for shadow model logits\n",
    "N, M, C = shadow_logits.shape\n",
    "shadow_gtl_probs_list = []\n",
    "\n",
    "for m in range(M):\n",
    "    model_logits = shadow_logits[:, m, :]  # shape (N, C)\n",
    "    probs = rmia_get_gtlprobs(model_logits, labels)\n",
    "    shadow_gtl_probs_list.append(probs)\n",
    "    print(f\"{len(shadow_gtl_probs_list)} shadow gtl probs calculated\")\n",
    "\n",
    "shadow_gtl_probs = np.stack(shadow_gtl_probs_list, axis=1)  # shape = (N, M)\n",
    "\n",
    "# Calculate the GTL Probabilities for the target logits\n",
    "target_gtl_probs = rmia_get_gtlprobs(target_logits, labels)\n",
    "print(f\"Target gtl_probs: {target_gtl_probs[:10]}, shape: {target_gtl_probs.shape}\")\n",
    "\n",
    "rmia_scores = rmia_vectorised(target_gtl_probs, shadow_gtl_probs, shadow_inmask, online=True, use_gpu_if_available=True)\n",
    "\n",
    "#----------------------------#\n",
    "#  Calculate Reference TAUC  #\n",
    "#----------------------------#\n",
    "# Reference tail AUC at fpr=0.1\n",
    "tauc_ref = calculate_tauc(rmia_scores, target_inmask, fpr=0.1)\n",
    "print(f\"tauc_ref@(0.1): {tauc_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34eca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------#\n",
    "#        Run study        #\n",
    "# ------------------------#\n",
    "\n",
    "fbd_args = FbdArgs(\n",
    "    rmia_scores=rmia_scores,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    shadow_gtl_probs=shadow_gtl_probs,\n",
    "    shadow_inmask=shadow_inmask,\n",
    "    target_inmask=target_inmask,\n",
    "    tauc_ref=tauc_ref,\n",
    ")\n",
    "\n",
    "# Specify which gpus to be used \n",
    "\n",
    "\n",
    "study = None \n",
    "if config is not None: \n",
    "    study = parallell_optimization(config, labels, fbd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_db = True\n",
    "if load_from_db:\n",
    "    study_cfg = config['fbd_study'] \n",
    "    db_path = os.path.join(study_cfg['root'], \"fbd_study.db\")\n",
    "    storage = f\"sqlite:///{db_path}\"\n",
    "    study = optuna.load_study(study_name=\"cifar10-resnet-fbd-815409b641\", storage=storage)\n",
    "\n",
    "if study is not None:\n",
    "    print(\"visualizing study\")\n",
    "    fig1 = optuna.visualization.plot_pareto_front(study)\n",
    "    fig1.update_layout(xaxis_title=\"Ï„@0.1\", yaxis_title=\"Accuracy\")\n",
    "    fig1.show()\n",
    "\n",
    "    fig2 = optuna.visualization.plot_param_importances(study)\n",
    "    fig2.show()\n",
    "else:\n",
    "    print(\"Study has not been run\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch import tensor, cat, save, load, optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "\n",
    "import src.study_handler as sh\n",
    "from src.utils import print_yaml, get_shadow_signals, calculate_tauc\n",
    "from LeakPro.leakpro.attacks.mia_attacks.rmia import rmia_vectorised, rmia_get_gtlprobs\n",
    "from src.save_load import loadTargetSignals, loadShadowModelSignals\n",
    "from src.models.resnet18_model import ResNet18\n",
    "from src.optimize_fbd_model import parallell_optimization, FbdArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68780cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------#\n",
    "#  Set device  #\n",
    "# -------------#\n",
    "sh.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {sh.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad8e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------#\n",
    "#  Load Study Config  #\n",
    "#---------------------#\n",
    "config = None\n",
    "with open(\"./study.yaml\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "print_yaml(f\"Initial study config: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------#\n",
    "#  Load Model Signals  #\n",
    "#----------------------#\n",
    "target_folder = config[\"fbd_study\"][\"target_folder\"]\n",
    "\n",
    "# Load target signals\n",
    "target_logits, target_inmask, metadata = loadTargetSignals(target_folder)\n",
    "print(f\"Target logits and inmask shapes: {target_logits.shape}, {target_inmask.shape}\")\n",
    "\n",
    "# Load processed shadow model signals\n",
    "sm_logits, sm_inmask = loadShadowModelSignals(target_folder)\n",
    "print(f\"Target logits and inmask shapes: {sm_logits.shape}, {sm_inmask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------#\n",
    "#  Update Study Config  #\n",
    "#-----------------------#\n",
    "print_yaml(\"Initial study config:\")\n",
    "print_yaml(config['fbd_study'])\n",
    "train_metadata = metadata[\"train\"]\n",
    "\n",
    "config['fbd_study'][\"epochs\"] = train_metadata[\"epochs\"]\n",
    "config['fbd_study'][\"batch_size\"] = train_metadata[\"batch_size\"]\n",
    "config['fbd_study'][\"momentum\"] = train_metadata[\"momentum\"]\n",
    "config['fbd_study'][\"learning_rate\"] = train_metadata[\"learning_rate\"]\n",
    "config['fbd_study'][\"t_max\"] = train_metadata[\"t_max\"]\n",
    "config['fbd_study'][\"weight_decay\"] = train_metadata[\"weight_decay\"]\n",
    "\n",
    "print_yaml(\"\\nUpdated study config:\")\n",
    "print_yaml(config['fbd_study'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce50bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------#\n",
    "#  Select Shadow Models  #\n",
    "#------------------------#\n",
    "sm_count = config['fbd_study']['shadow_model_count']\n",
    "print(f\"Randomly selecting {sm_count} to be used for the study.\")\n",
    "shadow_logits, shadow_inmask = get_shadow_signals(sm_logits, sm_inmask, sm_count)\n",
    "print(f\"Shape of selected_sm_logits: {shadow_logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------#\n",
    "#  Prepare dataset  #\n",
    "#-------------------#\n",
    "from src.dataset_handler import processDataset, loadDataset\n",
    "data_cfg = config['data']\n",
    "trainset, testset = loadDataset(data_cfg)\n",
    "\n",
    "# Will split the dataset to use the same in indices as the baseline target model\n",
    "train_dataset, test_dataset, train_indices, test_indices = processDataset(data_cfg, trainset, testset, in_indices_mask=target_inmask)\n",
    "\n",
    "# Retrieve the targets\n",
    "full_dataset = train_dataset.dataset\n",
    "labels = full_dataset.targets\n",
    "print(f\"Length of dataset targets/labels: {len(labels)}\")\n",
    "print(f\"First 10 targets/labels: {labels[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ccc16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------#\n",
    "#  Calculate Vulnerability score using RMIA  #\n",
    "#--------------------------------------------#\n",
    "# Calculate the GTL Probabilities for shadow model logits\n",
    "N, M, C = shadow_logits.shape\n",
    "shadow_gtl_probs_list = []\n",
    "\n",
    "for m in range(M):\n",
    "    model_logits = shadow_logits[:, m, :]  # shape (N, C)\n",
    "    probs = rmia_get_gtlprobs(model_logits, labels)\n",
    "    shadow_gtl_probs_list.append(probs)\n",
    "    print(f\"{len(shadow_gtl_probs_list)} shadow gtl probs calculated\")\n",
    "\n",
    "shadow_gtl_probs = np.stack(shadow_gtl_probs_list, axis=1)  # shape = (N, M)\n",
    "\n",
    "# Calculate the GTL Probabilities for the target logits\n",
    "target_gtl_probs = rmia_get_gtlprobs(target_logits, labels)\n",
    "print(f\"Target gtl_probs: {target_gtl_probs[:10]}, shape: {target_gtl_probs.shape}\")\n",
    "\n",
    "rmia_scores = rmia_vectorised(target_gtl_probs, shadow_gtl_probs, shadow_inmask, online=True, use_gpu_if_available=True)\n",
    "\n",
    "#----------------------------#\n",
    "#  Calculate Reference TAUC  #\n",
    "#----------------------------#\n",
    "# Reference tail AUC at fpr=0.1\n",
    "tauc_ref = calculate_tauc(rmia_scores, target_inmask, fpr=0.1)\n",
    "print(f\"tauc_ref@(0.1): {tauc_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504cdf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the RMIA score distribution\n",
    "plt.hist(rmia_scores, bins=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34eca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------#\n",
    "#        Run study        #\n",
    "# ------------------------#\n",
    "\n",
    "fbd_args = FbdArgs(\n",
    "    rmia_scores=rmia_scores,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    shadow_gtl_probs=shadow_gtl_probs,\n",
    "    shadow_inmask=shadow_inmask,\n",
    "    target_inmask=target_inmask,\n",
    "    tauc_ref=tauc_ref,\n",
    ")\n",
    "\n",
    "# Specify which gpus to be used \n",
    "gpu_ids = [0, 1]\n",
    "\n",
    "study = None \n",
    "if config is not None: \n",
    "    study = parallell_optimization(config, labels, gpu_ids, fbd_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97051e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------#\n",
    "#        Run study      COPY      #\n",
    "# ------------------------#\n",
    "import src.save_load as sl\n",
    "\n",
    "def run_optimization(config, gpu_id, trials, save_path): \n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    \n",
    "    study_cfg = config['fbd_study']\n",
    "\n",
    "    # Parallell storage setup\n",
    "    db_path = os.path.join(study_cfg['root'], \"fbd_study.db\")\n",
    "    storage = f\"sqlite:///{db_path}\"\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        study_name=study_cfg[\"study_name\"],\n",
    "        storage=storage,\n",
    "        load_if_exists=True,\n",
    "        directions=[\"minimize\", \"maximize\"]\n",
    "    )\n",
    "    \n",
    "    func = lambda trial: sh.fbd_objective(trial, rmia_scores, train_dataset, test_dataset,\n",
    "                                       config, shadow_gtl_probs, shadow_inmask,\n",
    "                                       target_inmask, tauc_ref, gpu_id, save_path)\n",
    "    \n",
    "    study.optimize(func, n_trials=trials)\n",
    "    \n",
    "    print(f\"Study '{study_cfg['study_name']}' completed on GPU {gpu_id}.\")\n",
    "    df = study.trials_dataframe() \n",
    "    df.to_csv(os.path.join(save_path, f\"results_gpu_{gpu_id}.csv\"), index=False) \n",
    "    print(f\"ðŸ“„ Results saved to {os.path.join(save_path, f'results_gpu_{gpu_id}.csv')}\")\n",
    "\n",
    "def parallell_optimization(config): \n",
    "    study_cfg = config['fbd_study'] \n",
    "\n",
    "    metadata = sl.buildStudyMetadata(study_cfg, config['data']) \n",
    "    _, save_path = sl.saveStudy(metadata, savePath=study_cfg['root'], labels=labels) \n",
    "    # Specify which gpus to be used \n",
    "    gpu_ids = [0, 1]\n",
    "    assert study_cfg[\"trials\"] % len(gpu_ids) == 0, f\"amount of trials {study_cfg['trials']} cannot be equally split among {len(gpu_ids)}\"\n",
    "    trials = study_cfg[\"trials\"] // len(gpu_ids)\n",
    "    processes = [multiprocessing.Process(target=run_optimization, args=(config, gpu_id, trials, save_path)) for gpu_id in gpu_ids] \n",
    "    for p in processes:\n",
    "        p.start() \n",
    "    for p in processes:\n",
    "        p.join()\n",
    "        \n",
    "    db_path = os.path.join(study_cfg['root'], \"fbd_study.db\")\n",
    "    storage = f\"sqlite:///{db_path}\"\n",
    "    study = optuna.load_study(study_name=study_cfg[\"study_name\"], storage=storage)\n",
    "    return study\n",
    "        \n",
    "study = None \n",
    "if config is not None: \n",
    "    study = parallell_optimization(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211a6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_journal = False\n",
    "\n",
    "if load_from_journal:\n",
    "    journal_path = \"study/cifar10-resnet-fbd-lira-aa5cec7773/journal.log\"\n",
    "    \n",
    "    # Re-open storage\n",
    "    storage = JournalStorage(JournalFileBackend(journal_path))\n",
    "    \n",
    "    # Load the study by name (must match what was used originally)\n",
    "    study = optuna.load_study(\n",
    "        study_name=\"cifar10-resnet-fbd\",\n",
    "        storage=storage\n",
    "    )\n",
    "    print(\"study loaded: cifar10-resnet-fbd\")\n",
    "\n",
    "if study is not None:\n",
    "    print(\"visualizing study\")\n",
    "    fig1 = optuna.visualization.plot_pareto_front(study)\n",
    "    fig1.update_layout(xaxis_title=\"Ï„@0.1\", yaxis_title=\"Accuracy\")\n",
    "    fig1.show()\n",
    "\n",
    "    fig2 = optuna.visualization.plot_param_importances(study)\n",
    "    fig2.show()\n",
    "else:\n",
    "    print(\"Study has not been run\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

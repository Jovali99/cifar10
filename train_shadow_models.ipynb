{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import optuna\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from src.save_load import buildAuditMetadata, saveAudit\n",
    "from src.train_models import trainTargetModel\n",
    "from src.visualize_model import VisualizeModel\n",
    "from src.utils import print_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7397c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- #\n",
    "#   Load Audit yaml   #\n",
    "# ------------------- #\n",
    "config = None\n",
    "with open(\"./audit.yaml\") as file:\n",
    "    audit_config = yaml.safe_load(file)\n",
    "\n",
    "print(\"-------------- Audit config --------------\")\n",
    "print_yaml(audit_config['audit'])\n",
    "print_yaml(audit_config['target'])\n",
    "\n",
    "# -------------------------------- #\n",
    "#  Load target model and metadata  #\n",
    "# -------------------------------- #\n",
    "target_folder = \"resnet18-abeb4ef939\"\n",
    "target_path = os.path.join(\"target\", target_folder)\n",
    "\n",
    "# Metadata and target .pkl path for audit config\n",
    "target_model_path = os.path.join(target_path, \"target_model.pkl\")\n",
    "target_metadata_path = os.path.join(target_path, \"target_metadata.pkl\")\n",
    "\n",
    "# Update the audit config\n",
    "audit_config['target']['target_folder'] = target_path\n",
    "\n",
    "print(\"\\n-------------- Updated audit config --------------\")\n",
    "print_yaml(audit_config['audit'])\n",
    "print_yaml(audit_config['target'])\n",
    "\n",
    "# ------------------- #\n",
    "#   Load Train yaml   #\n",
    "# ------------------- #\n",
    "config = None\n",
    "with open(\"./train.yaml\") as file:\n",
    "    train_config = yaml.safe_load(file)\n",
    "    \n",
    "print(\"\\n-------------- Train config --------------\")\n",
    "print_yaml(train_config['train'])\n",
    "\n",
    "# Target Metadata .json\n",
    "metadata_path = os.path.join(target_path, \"target_metadata.pkl\")\n",
    "metadata_path = os.path.join(target_path, \"metadata.json\")\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "# Update the train config with target metadata (learning rate, batch size, etc)\n",
    "train_config['train']['epochs'] = metadata['train']['epochs']\n",
    "train_config['train']['batch_size'] = metadata['train']['batch_size']\n",
    "train_config['train']['learning_rate'] = metadata['train']['learning_rate']\n",
    "train_config['train']['momentum'] = metadata['train']['momentum']\n",
    "\n",
    "train_config['run']['log_dir'] = target_path\n",
    "\n",
    "print(\"\\n-------------- Updated train config --------------\")\n",
    "print_yaml(train_config['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ebf782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LeakPro.leakpro.schemas import LeakProConfig\n",
    "from LeakPro.leakpro.attacks.mia_attacks.lira import AttackLiRA\n",
    "from LeakPro.leakpro.attacks.utils.shadow_model_handler import ShadowModelHandler\n",
    "from LeakPro.leakpro.input_handler.mia_handler import MIAHandler\n",
    "from src.cifar_handler import CifarInputHandler\n",
    "# ----------------- #\n",
    "#   Setup LeakPro   #\n",
    "# ----------------- #\n",
    "\n",
    "# Intizializing\n",
    "leakpro_configs = LeakProConfig(**audit_config)\n",
    "print(\"-------- LeakPro Configs --------\")\n",
    "print_yaml(leakpro_configs)\n",
    "\n",
    "handler = MIAHandler(leakpro_configs, CifarInputHandler)\n",
    "\n",
    "configs = handler.configs.audit.attack_list[0]\n",
    "print(\"-------- Attack Configs --------\")\n",
    "print_yaml(configs)\n",
    "\n",
    "attack = AttackLiRA(handler=handler, configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------- #\n",
    "#   Train the Shadow models   #\n",
    "# --------------------------- #\n",
    "\n",
    "#Set number of shadow models to train\n",
    "num_shadow_models = configs[\"num_shadow_models\"]\n",
    "#Set online flag\n",
    "online = configs[\"online\"]\n",
    "\n",
    "attack_data_indices = attack.sample_indices_from_population(include_train_indices = online,\n",
    "                                                        include_test_indices = online)\n",
    "\n",
    "training_data_fraction = attack.training_data_fraction\n",
    "\n",
    "smh = ShadowModelHandler(handler)\n",
    "smh.epochs = train_config[\"train\"][\"epochs\"]\n",
    "smh.batch_size = train_config['train']['batch_size']\n",
    "smh.learning_rate = train_config['train']['learning_rate']\n",
    "smh.momentum = train_config['train']['momentum']\n",
    "\n",
    "shadow_model_indices = smh.create_shadow_models(num_models = num_shadow_models,\n",
    "                                                                shadow_population =  attack_data_indices,\n",
    "                                                                training_fraction = training_data_fraction,\n",
    "                                                                online = online,\n",
    "                                                                #verbose = False,\n",
    "                                                                #incremental = INCREMENTAL, \n",
    "                                                                #shuffle_shift = SHUFFLE_SHIFT\n",
    "                                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13dc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- #\n",
    "#   Load Shadow Models   #\n",
    "# -------------------------------- #\n",
    "#Get shadow models\n",
    "shadow_models, _ = smh.get_shadow_models(shadow_model_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------- #\n",
    "#   Extract Shadow model Signals   #\n",
    "# -------------------------------- #\n",
    "\n",
    "# Get the audit dataset from the attack\n",
    "audit_dataset = attack.audit_dataset\n",
    "true_labels = handler.get_labels(audit_dataset[\"data\"])\n",
    "print(f\"\\nTrue labels fetched: {true_labels[:10]}\")\n",
    "\n",
    "# Fetch and rescale shadow model logits\n",
    "shadow_models_logits = []\n",
    "for indx in shadow_model_indices:\n",
    "    shadow_models_logits.append(smh.load_logits(indx=indx))\n",
    "rescaled_sm_logits = np.array([attack.rescale_logits(x, true_labels) for x in shadow_models_logits])\n",
    "\n",
    "print(\"\\n--------- Shadow models logits extracted ---------\")\n",
    "print(rescaled_sm_logits[0])\n",
    "print(f\"Shadow model logits shape: {rescaled_sm_logits.shape}\")\n",
    "\n",
    "# Extract target model logits\n",
    "\n",
    "target_logits = smh.load_logits(name=\"target\")\n",
    "rescaled_target_logits = attack.rescale_logits(target_logits, true_labels)\n",
    "\n",
    "print(\"\\n--------- target model logits extracted ---------\")\n",
    "print(rescaled_target_logits[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the in indices mask for shadow models\n",
    "in_indices_masks = ShadowModelHandler(handler).get_in_indices_mask(shadow_model_indices, audit_dataset[\"data\"])#.astype(int)\n",
    "\n",
    "audit_data_indices = audit_dataset[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ #\n",
    "#   Save logits & indices mask   #\n",
    "# ------------------------------ #\n",
    "metadata = buildAuditMetadata(train_config, audit_config)\n",
    "\n",
    "hash_id, save_dir = saveAudit(metadata, rescaled_target_logits, rescaled_sm_logits, in_indices_masks, audit_data_indices)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
